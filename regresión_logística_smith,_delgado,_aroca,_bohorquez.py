# -*- coding: utf-8 -*-
"""Regresión Logística - Smith, Delgado, Aroca, Bohorquez.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C1WElUdv40m4MDXJP2-0-YB-1Kv1HB8a
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

# Cargar el archivo csv
data = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRVINnllp2LT8adKlW74ePzhvETJ_KOL-4HLViH5VQdWahDHO1RnHqJZLSbq4bWAA/pub?gid=2112414570&single=true&output=csv')

# Visualizar los datos
print(data.head())
print(data.info())
print(data.describe())

# Target reparaciones
x = data.drop(['CreditScore','Income','LoanAmount'], axis=1)
y = data['Default']

# Dividir el data
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Estandarizar los datos
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

# Crear el modelo
Logistic_model = LogisticRegression()

# Entrenar el modelo
Logistic_model.fit(x_train_scaled, y_train)

# Realizar predicciones de la prueba
y_pred = Logistic_model.predict(x_test_scaled)

# Crear la matriz de confusion
conf_matrix = confusion_matrix(y_test, y_pred)

# Visualización
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

#Imprimir el reporte
print(classification_report(y_test, y_pred))

#Imprimir exactitud del modelo
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy * 100:.2f}%')

"""# DESARROLLO Y ANALISIS
### importacion de librerias
cada libreria tiene un proposito fundamental en eset caso
*  numpy: Para operaciones numéricas.
* pandas: Para manipulación y análisis de datos.
* matplotlib y seaborn: Para visualización de datos.
* sklearn: Para modelado y evaluación de modelos de machine learning.
### Carga de archivos
Al usar: data = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRVINnllp2LT8adKlW74ePzhvETJ_KOL-4HLViH5VQdWahDHO1RnHqJZLSbq4bWAA/pub?gid=2112414570&single=true&output=csv')
Se carga el conjunto de datos desde un archivo CSV alojado en Google Sheets. Este archivo contiene información sobre clientes y sus préstamos.
### Visualizacion de datos
* data.head(): Muestra las primeras 5 filas del conjunto de datos.
* data.info(): Proporciona un resumen de la estructura del DataFrame, incluyendo el tipo de datos y valores nulos.
* data.describe(): Muestra estadísticas descriptivas como media, desviación estándar, mínimos y máximos.
### Preparacion de datos
* x: Contiene las características (features) del conjunto de datos, excluyendo ‘CreditScore’, ‘Income’ y ‘LoanAmount’.
* y: Contiene la variable objetivo (target), que es ‘Default’, indicando si un cliente incumplió el préstamo.
### Divicion del conjunto de datos
Con: x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
Se divide el conjunto de datos en entrenamiento (80%) y prueba (20%). La semilla aleatoria (random_state) asegura que la división sea reproducible.
### Estandarizacion de los datos
* StandardScaler: Estandariza las características para que tengan media 0 y desviación estándar 1.
* fit_transform: Ajusta el escalador a los datos de entrenamiento y los transforma.
* transform: Transforma los datos de prueba usando el mismo escalador ajustado.
### Creacion y entrenamiento del modelo
* LogisticRegression: Crea un modelo de regresión logística.
* fit: Entrena el modelo usando los datos de entrenamiento estandarizados.
### Prediccion y evaluacion del modelo
* predict: Realiza predicciones sobre los datos de prueba.
* confusion_matrix: Crea una matriz de confusión para evaluar el desempeño del modelo.
### Visualizacion de la matriz de confusión
* plt.figure: Crea una nueva figura para la visualización.
* sns.heatmap: Genera un mapa de calor para la matriz de confusión.
* plt.xlabel, plt.ylabel, plt.title: Etiquetan los ejes y el título del gráfico.
* plt.show: Muestra el gráfico.
### Reporte de clasificacion y exactitud del modelo
* classification_report: Proporciona un reporte detallado de métricas como precisión, recall y F1-score.
* accuracy_score: Calcula la exactitud del modelo.
* print: Muestra el reporte de clasificación y la exactitud en la consola.

# RESULTADOS Y ANALISIS
### Resultados

*  Matriz de confusión: La matriz de confusión muestra el desempeño del modelo en términos de verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos.
*  Reporte de clasificación: El reporte de clasificación incluye métricas como precisión, recall y F1-score para cada clase.
* Exactitud del modelo: La exactitud del modelo es del 83%.
### Analisis
* El modelo de regresión logística entrenado muestra un buen desempeño con una exactitud del 83%. La matriz de confusión y el reporte de clasificación indican que el modelo es más preciso en la predicción de la clase 0 (no incumplimiento) en comparación con la clase 1 (incumplimiento). Esto podría deberse a un desbalance en las clases del conjunto de datos.

# **CONCLUSIONES**

**Aprendizajes:**

*   **Estandarización:** Nos dimos cuenta de que es importante "normalizar" los
datos, o sea, hacer que todos tengan un rango similar para que el modelo funcione mejor.
*   **División de los datos:** Aprendimos que es necesario separar los datos en dos partes (entrenamiento y prueba) para que el modelo no "memorice" todo y pueda predecir bien cuando le damos datos nuevos.
*   **Evaluación del modelo:** Usamos la matriz de confusión y el reporte de clasificación para ver qué tan bien predijo el modelo, y aprendimos que la exactitud no es lo único que importa.


**Desafíos:**

*   **Preparar los datos:** Fue un poco complicado decidir qué columnas usar y cuáles no, ya que esto afecta los resultados del modelo.

*   **Interpretar los resultados:** Aunque el código nos dio métricas como la precisión, fue difícil entender cómo mejorar el modelo con esos números.

*   **Decidir cuándo el modelo es bueno: **A veces, aunque la exactitud era alta, el modelo no era tan bueno en predecir ciertos casos. Aprendimos que siempre hay que revisar más de una métrica.

Logramos entrenar un modelo básico, pero también vimos que hay muchos detalles que pueden afectar el resultado, y que no solo es seguir pasos, sino entender lo que se está haciendo.
"""